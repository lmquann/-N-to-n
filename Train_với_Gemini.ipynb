{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmquann/-N-to-n/blob/main/Train_v%E1%BB%9Bi_Gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iqFbA0FSKeO",
        "outputId": "834c6173-4359-4525-9ef3-3552b266e056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lỗi: Vui lòng đặt biến môi trường 'GEMINI_API_KEY' với khóa API Gemini của bạn.\n",
            "Ví dụ: export GEMINI_API_KEY='...' trên Linux/macOS hoặc set GEMINI_API_KEY=... trên Windows.\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "import re\n",
        "\n",
        "# --- CẤU HÌNH ---\n",
        "# THAY THẾ 'YOUR_GEMINI_API_KEY' BẰNG KHÓA API THỰC TẾ CỦA BẠN HOẶC ĐẶT BIẾN MÔI TRƯỜNG\n",
        "# Để an toàn, bạn nên đặt khóa API trong biến môi trường GEMINI_API_KEY\n",
        "# Ví dụ: export GEMINI_API_KEY='...' (trên Linux/macOS) hoặc set GEMINI_API_KEY=... (trên Windows)\n",
        "# genai.configure(api_key=\"YOUR_GEMINI_API_KEY\") # Cách không khuyến nghị cho production\n",
        "# Lấy Khoá API\n",
        "genai.configure(api_key='AIzaSyD0zlXkgaLTTUIOrueypy-wAoZHmbCqyEY')\n",
        "\n",
        "# Khởi tạo mô hình Gemini 2.5 flash\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "# Đường dẫn đến thư mục chứa các tệp bài học đã tách\n",
        "LESSONS_DIR = 'data_lessons/'\n",
        "# Mô hình Embeddings của Gemini\n",
        "EMBEDDING_MODEL = \"models/embedding-001\" # Hoặc \"models/text-embedding-004\" nếu có\n",
        "# Kích thước chunk tối đa (số từ)\n",
        "MAX_CHUNK_WORDS = 250\n",
        "# Mức độ chồng chéo giữa các chunk (số từ)\n",
        "OVERLAP_WORDS = 50\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CÁC HÀM HỖ TRỢ ---\n",
        "\n",
        "def get_embedding(text, model=EMBEDDING_MODEL, task_type=\"retrieval_document\"):\n",
        "    \"\"\"\n",
        "    Tạo embedding cho văn bản bằng API Gemini.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = genai.embed_content(\n",
        "            model=model,\n",
        "            content=text,\n",
        "            task_type=task_type # Quan trọng: chỉ định loại tác vụ cho embeddings\n",
        "        )\n",
        "        return response['embedding']\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi khi tạo embedding cho văn bản '{text[:50]}...': {e}\")\n",
        "        return None\n",
        "\n",
        "def simple_chunker(text, max_words=MAX_CHUNK_WORDS, overlap_words=OVERLAP_WORDS):\n",
        "    \"\"\"\n",
        "    Chia văn bản thành các đoạn (chunks) đơn giản dựa trên số từ.\n",
        "    \"\"\"\n",
        "    words = re.findall(r'\\b\\w+\\b', text.lower()) # Tách từ, bỏ qua dấu câu\n",
        "    chunks = []\n",
        "    current_pos = 0\n",
        "\n",
        "    while current_pos < len(words):\n",
        "        chunk_words = words[current_pos : current_pos + max_words]\n",
        "        chunk = ' '.join(chunk_words)\n",
        "        if chunk:\n",
        "            chunks.append(chunk)\n",
        "\n",
        "        # Di chuyển con trỏ cho đoạn tiếp theo, có tính đến overlap\n",
        "        current_pos += (max_words - overlap_words)\n",
        "        if current_pos >= len(words) and len(chunk_words) == max_words:\n",
        "            # Nếu đã hết từ và đoạn cuối cùng đủ kích thước, thoát\n",
        "            break\n",
        "        elif current_pos >= len(words) and len(chunk_words) < max_words:\n",
        "            # Nếu đoạn cuối cùng nhỏ hơn max_words, đã xử lý xong\n",
        "            break\n",
        "        elif current_pos < len(words) and len(words[current_pos:]) < (max_words - overlap_words) and len(words[current_pos:]) > 0:\n",
        "            # Đảm bảo đoạn cuối cùng không quá ngắn nếu còn từ\n",
        "            if len(words) - current_pos > 0 and len(words) - current_pos < max_words:\n",
        "                chunks.append(' '.join(words[current_pos:]))\n",
        "                break\n",
        "\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TQWHs_14SSnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- QUY TRÌNH CHÍNH ---\n",
        "\n",
        "def process_lessons_for_embeddings(lessons_dir):\n",
        "    \"\"\"\n",
        "    Đọc từng tệp bài học, chia nhỏ và tạo embeddings.\n",
        "    \"\"\"\n",
        "    all_chunks_with_embeddings = []\n",
        "\n",
        "    # Duyệt qua các tệp bài học trong thư mục\n",
        "    for filename in sorted(os.listdir(lessons_dir)):\n",
        "        if filename.endswith(\".txt\") and filename.startswith(\"bai_\"):\n",
        "            filepath = os.path.join(lessons_dir, filename)\n",
        "\n",
        "            # Trích xuất số bài và tên bài từ tên tệp\n",
        "            match = re.match(r\"bai_(\\d+)_([^\\.]+)\\.txt\", filename)\n",
        "            lesson_number = match.group(1) if match else \"Unknown\"\n",
        "            lesson_name = match.group(2).replace('_', ' ') if match else \"Unknown\"\n",
        "\n",
        "            print(f\"\\nĐang xử lý bài: {lesson_name} (Số: {lesson_number}) từ '{filename}'\")\n",
        "\n",
        "            try:\n",
        "                with open(filepath, 'r', encoding='utf-8') as f:\n",
        "                    lesson_content = f.read()\n",
        "\n",
        "                # Chia nhỏ nội dung bài học thành các đoạn (chunks)\n",
        "                chunks = simple_chunker(lesson_content)\n",
        "\n",
        "                print(f\"  -> Đã chia thành {len(chunks)} đoạn.\")\n",
        "\n",
        "                for i, chunk in enumerate(chunks):\n",
        "                    # Tạo embedding cho mỗi đoạn\n",
        "                    embedding = get_embedding(chunk)\n",
        "\n",
        "                    if embedding:\n",
        "                        # Lưu trữ đoạn văn bản, embedding và metadata\n",
        "                        all_chunks_with_embeddings.append({\n",
        "                            \"text_content\": chunk,\n",
        "                            \"embedding\": embedding,\n",
        "                            \"metadata\": {\n",
        "                                \"lesson_number\": lesson_number,\n",
        "                                \"lesson_name\": lesson_name,\n",
        "                                \"source_file\": filename,\n",
        "                                \"chunk_id\": f\"{lesson_number}-{i+1}\"\n",
        "                            }\n",
        "                        })\n",
        "                        print(f\"    - Đã tạo embedding cho đoạn {i+1} (Dài {len(chunk.split())} từ).\")\n",
        "                    else:\n",
        "                        print(f\"    - Bỏ qua đoạn {i+1} do lỗi tạo embedding.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Lỗi khi đọc hoặc xử lý tệp '{filename}': {e}\")\n",
        "\n",
        "    return all_chunks_with_embeddings\n",
        "\n"
      ],
      "metadata": {
        "id": "KydWT2zlSWD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CHẠY QUY TRÌNH ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Bắt đầu quá trình tạo embeddings cho dữ liệu sách giáo khoa...\")\n",
        "    embedded_data = process_lessons_for_embeddings(LESSONS_DIR)\n",
        "\n",
        "    print(f\"\\nHoàn tất tạo embeddings cho tổng cộng {len(embedded_data)} đoạn văn bản.\")\n",
        "\n",
        "    if embedded_data:\n",
        "        print(\"\\n--- Cấu trúc dữ liệu đã tạo (một ví dụ): ---\")\n",
        "        # In một ví dụ để bạn hình dung\n",
        "        example = embedded_data[0]\n",
        "        print(f\"Nội dung đoạn: \\\"{example['text_content'][:200]}...\\\"\")\n",
        "        print(f\"Kích thước Embedding: {len(example['embedding'])}\")\n",
        "        print(f\"Metadata: {example['metadata']}\")\n",
        "        print(\"\\n--- Các bước tiếp theo: ---\")\n",
        "        print(\"1. Lưu trữ 'embedded_data' này vào một cơ sở dữ liệu vector (ví dụ: ChromaDB, Qdrant, Pinecone).\")\n",
        "        print(\"   Mỗi phần tử trong 'embedded_data' là một tài liệu bạn sẽ thêm vào cơ sở dữ liệu vector.\")\n",
        "        print(\"2. Khi người dùng đặt câu hỏi, tạo embedding cho câu hỏi đó bằng cùng mô hình Gemini.\")\n",
        "        print(\"3. Tìm kiếm các embedding gần nhất trong cơ sở dữ liệu vector của bạn để truy xuất thông tin liên quan.\")\n",
        "        print(\"4. Sử dụng thông tin truy xuất được để tăng cường cho lời nhắc gửi đến API Gemini (cho tác vụ tạo văn bản).\")\n",
        "    else:\n",
        "        print(\"Không có dữ liệu nào được xử lý. Vui lòng kiểm tra lại thư mục và tệp đầu vào.\")"
      ],
      "metadata": {
        "id": "ShH1ydZtSTou"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}